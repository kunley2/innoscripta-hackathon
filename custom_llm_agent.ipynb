{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5f8741",
   "metadata": {},
   "source": [
    "# Custom LLM Agent\n",
    "\n",
    "This notebook goes through how to create your own custom LLM agent.\n",
    "\n",
    "An LLM agent consists of three parts:\n",
    "\n",
    "- PromptTemplate: This is the prompt template that can be used to instruct the language model on what to do\n",
    "- LLM: This is the language model that powers the agent\n",
    "- `stop` sequence: Instructs the LLM to stop generating as soon as this string is found\n",
    "- OutputParser: This determines how to parse the LLMOutput into an AgentAction or AgentFinish object\n",
    "\n",
    "\n",
    "The LLMAgent is used in an AgentExecutor. This AgentExecutor can largely be thought of as a loop that:\n",
    "1. Passes user input and any previous steps to the Agent (in this case, the LLMAgent)\n",
    "2. If the Agent returns an `AgentFinish`, then return that directly to the user\n",
    "3. If the Agent returns an `AgentAction`, then use that to call a tool and get an `Observation`\n",
    "4. Repeat, passing the `AgentAction` and `Observation` back to the Agent until an `AgentFinish` is emitted.\n",
    "    \n",
    "`AgentAction` is a response that consists of `action` and `action_input`. `action` refers to which tool to use, and `action_input` refers to the input to that tool. `log` can also be provided as more context (that can be used for logging, tracing, etc).\n",
    "\n",
    "`AgentFinish` is a response that contains the final message to be sent back to the user. This should be used to end an agent run.\n",
    "        \n",
    "In this notebook we walk through how to create a custom LLM agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4812c",
   "metadata": {},
   "source": [
    "## Set up environment\n",
    "\n",
    "Do necessary imports, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af9734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0253f",
   "metadata": {},
   "source": [
    "## Set up tool\n",
    "\n",
    "Set up any tools the agent may want to use. This may be necessary to put in the prompt (so that the agent knows to use these tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92eba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"3ecbf05c8be8ee4d8f17efef348854f1922f61ee30462f53c6f400ac3466a2cd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "becda2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which tools the agent can use to answer user queries\n",
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a075c",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "\n",
    "This instructs the agent on what to do. Generally, the template should incorporate:\n",
    "    \n",
    "- `tools`: which tools the agent has access and how and when to call them.\n",
    "- `intermediate_steps`: These are tuples of previous (`AgentAction`, `Observation`) pairs. These are generally not passed directly to the model, but the prompt template formats them in a specific way.\n",
    "- `input`: generic user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339b1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd969d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "798ef9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a1af3",
   "metadata": {},
   "source": [
    "## Output Parser\n",
    "\n",
    "The output parser is responsible for parsing the LLM output into `AgentAction` and `AgentFinish`. This usually depends heavily on the prompt used.\n",
    "\n",
    "This is where you can change the parsing to do retries, handle whitespace, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6fe0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d278706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170587b1",
   "metadata": {},
   "source": [
    "## Set up LLM\n",
    "\n",
    "Choose the LLM you want to use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d4c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeab5e4",
   "metadata": {},
   "source": [
    "## Define the stop sequence\n",
    "\n",
    "This is important because it tells the LLM when to stop generation.\n",
    "\n",
    "This depends heavily on the prompt and model you are using. Generally, you want this to be whatever token you use in the prompt to denote the start of an `Observation` (otherwise, the LLM may hallucinate an observation for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be9f65",
   "metadata": {},
   "source": [
    "## Set up the Agent\n",
    "\n",
    "We can now combine everything to set up our agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1cc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4f5092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a5326",
   "metadata": {},
   "source": [
    "## Use the Agent\n",
    "\n",
    "Now we can use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490604e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653b1617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7334d5fc0b05839083058ecb48fd1b70 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7334d5fc0b05839083058ecb48fd1b70 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7334d5fc0b05839083058ecb48fd1b70 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 09:01:26 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '5139', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149743', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': '7334d5fc0b05839083058ecb48fd1b70', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc1d164f7e5385-PMO', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to find out more about Amazon.com Inc\n",
      "Action: Search\n",
      "Action Input: Amazon.com Inc United States\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mOnline shopping from a great selection at USA Inc Store.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 09fb76f23cd7304b7c6ead0a5167930c in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 09fb76f23cd7304b7c6ead0a5167930c in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 09fb76f23cd7304b7c6ead0a5167930c in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 09:01:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '132', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149744', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': '09fb76f23cd7304b7c6ead0a5167930c', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc1d787fda5385-PMO', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to find out more about the products they offer\n",
      "Action: Search\n",
      "Action Input: Amazon.com Inc products\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mOnline shopping from a great selection at All Departments Store.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out more about the keywords associated with Amazon.com Inc\n",
      "Action: Search\n",
      "Action Input: Amazon.com Inc keywords\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mTo make your book easier to find on Amazon, you need keywords that accurately portray your book's content and reflect the words customers will use when they ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b42c2eb1fc7b5543ad0ddb1de8ed5627 in your email.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b42c2eb1fc7b5543ad0ddb1de8ed5627 in your email.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID b42c2eb1fc7b5543ad0ddb1de8ed5627 in your email.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 09:01:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-hihyni2nbrzuogrt6uwqqgco', 'openai-processing-ms': '293', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-limit-tokens': '150000', 'x-ratelimit-remaining-requests': '59', 'x-ratelimit-remaining-tokens': '149743', 'x-ratelimit-reset-requests': '1s', 'x-ratelimit-reset-tokens': '102ms', 'x-request-id': 'b42c2eb1fc7b5543ad0ddb1de8ed5627', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbc1de21d235385-PMO', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to find some images of their products\n",
      "Action: Search\n",
      "Action Input: Amazon.com Inc images\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mImages and Videos · Logos · Amazon History · Amazon Services · Devices · Fulfillment and Delivery · Physical Retail · Physical Retail Technologies · Seasonal and Events.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Arg, Amazon.com Inc be a big online store with a great selection o' products, keywords, an' images.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor.run(\"give me some information about amazon.con Inc which is located in united states, their producs, some keywords and some images of their products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "528d4977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Arg, Amazon.com Inc be a big online store with a great selection o' products, keywords, an' images.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4a078",
   "metadata": {},
   "source": [
    "## Adding Memory\n",
    "\n",
    "If you want to add memory to the agent, you'll need to:\n",
    "\n",
    "1. Add a place in the custom prompt for the chat_history\n",
    "2. Add a memory object to the agent executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94fffda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template_with_history = \"\"\"Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to speak as a pirate when giving your final answer. Use lots of \"Arg\"s\n",
    "\n",
    "Previous conversation history:\n",
    "{history}\n",
    "\n",
    "New question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f58488d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_history = CustomPromptTemplate(\n",
    "    template=template_with_history,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d28d4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt_with_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e37b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97ea1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5ad69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory=ConversationBufferWindowMemory(k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7b5c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ec4c39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find out what Amazon sells in the US\n",
      "Action: Search\n",
      "Action Input: Main products of Amazon.com Inc in United States\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mAmazon.com is an ecommerce platform that sells many product lines, including media (books, movies, music, and software), apparel, baby products, consumer electronics, beauty products, gourmet food, groceries, health and personal care products, industrial & scientific supplies, kitchen items, jewelry, watches, lawn and ...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to narrow down the list of products\n",
      "Action: Search\n",
      "Action Input: Specific products of Amazon.com Inc in United States\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThis is a list of products and services offered by American corporation Amazon. Contents. 1 Retail goods; 2 Amazon Prime; 3 Consumer electronics ...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Amazon sells retail goods, Amazon Prime, consumer electronics, home & garden products, toys, sports & outdoors items, health & personal care products, and more in the United States. Arg!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Amazon sells retail goods, Amazon Prime, consumer electronics, home & garden products, toys, sports & outdoors items, health & personal care products, and more in the United States. Arg!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"what are the main products of amazon.com Inc in United States?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2ba45bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: I need to find a website with images of Amazon's products.\n",
      "Action: Search\n",
      "Action Input: Amazon products images\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mMAIN images must be professional photographs of the actual product (graphics, illustrations, mockups, or placeholders are not allowed). They must not show ...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Ye can find the images ye be needin' at AMZ One Step. Arg!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ye can find the images ye be needin' at AMZ One Step. Arg!\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"Could you give me some url of images of these products?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd820a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "18784188d7ecd866c0586ac068b02361a6896dc3a29b64f5cc957f09c590acef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
